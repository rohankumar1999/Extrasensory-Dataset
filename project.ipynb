{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 users data.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utilize.feature_selection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/Checkout/Downloads/ExtraSensory-master/project.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Checkout/Downloads/ExtraSensory-master/project.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutilize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Checkout/Downloads/ExtraSensory-master/project.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutilize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Checkout/Downloads/ExtraSensory-master/project.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutilize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Checkout/Downloads/ExtraSensory-master/project.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutilize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtest\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utilize.feature_selection'"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from utilize.data import *\n",
    "from utilize.transform import *\n",
    "from utilize.plot import *\n",
    "from utilize.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the data from Extrasenory dataset\n",
    "X, y, M, user_index, feature_names, label_names = load_all_data(['1155FF54-63D3-4AB2-9863-8385D0BD0A13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-Domain Columns:\n",
      "raw_acc:magnitude_stats:mean\n",
      "raw_acc:magnitude_stats:std\n",
      "raw_acc:magnitude_stats:moment3\n",
      "raw_acc:magnitude_stats:moment4\n",
      "raw_acc:magnitude_stats:percentile25\n",
      "raw_acc:magnitude_stats:percentile50\n",
      "raw_acc:magnitude_stats:percentile75\n",
      "raw_acc:magnitude_stats:value_entropy\n",
      "raw_acc:magnitude_stats:time_entropy\n",
      "raw_acc:magnitude_spectrum:spectral_entropy\n",
      "raw_acc:3d:mean_x\n",
      "raw_acc:3d:mean_y\n",
      "raw_acc:3d:mean_z\n",
      "raw_acc:3d:std_x\n",
      "raw_acc:3d:std_y\n",
      "raw_acc:3d:std_z\n",
      "raw_acc:3d:ro_xy\n",
      "raw_acc:3d:ro_xz\n",
      "raw_acc:3d:ro_yz\n",
      "proc_gyro:magnitude_stats:mean\n",
      "proc_gyro:magnitude_stats:std\n",
      "proc_gyro:magnitude_stats:moment3\n",
      "proc_gyro:magnitude_stats:moment4\n",
      "proc_gyro:magnitude_stats:percentile25\n",
      "proc_gyro:magnitude_stats:percentile50\n",
      "proc_gyro:magnitude_stats:percentile75\n",
      "proc_gyro:magnitude_stats:value_entropy\n",
      "proc_gyro:magnitude_stats:time_entropy\n",
      "proc_gyro:magnitude_spectrum:spectral_entropy\n",
      "proc_gyro:3d:mean_x\n",
      "proc_gyro:3d:mean_y\n",
      "proc_gyro:3d:mean_z\n",
      "proc_gyro:3d:std_x\n",
      "proc_gyro:3d:std_y\n",
      "proc_gyro:3d:std_z\n",
      "proc_gyro:3d:ro_xy\n",
      "proc_gyro:3d:ro_xz\n",
      "proc_gyro:3d:ro_yz\n",
      "raw_magnet:magnitude_stats:mean\n",
      "raw_magnet:magnitude_stats:std\n",
      "raw_magnet:magnitude_stats:moment3\n",
      "raw_magnet:magnitude_stats:moment4\n",
      "raw_magnet:magnitude_stats:percentile25\n",
      "raw_magnet:magnitude_stats:percentile50\n",
      "raw_magnet:magnitude_stats:percentile75\n",
      "raw_magnet:magnitude_stats:value_entropy\n",
      "raw_magnet:magnitude_stats:time_entropy\n",
      "raw_magnet:magnitude_spectrum:spectral_entropy\n",
      "raw_magnet:3d:mean_x\n",
      "raw_magnet:3d:mean_y\n",
      "raw_magnet:3d:mean_z\n",
      "raw_magnet:3d:std_x\n",
      "raw_magnet:3d:std_y\n",
      "raw_magnet:3d:std_z\n",
      "raw_magnet:3d:ro_xy\n",
      "raw_magnet:3d:ro_xz\n",
      "raw_magnet:3d:ro_yz\n",
      "watch_acceleration:magnitude_stats:mean\n",
      "watch_acceleration:magnitude_stats:std\n",
      "watch_acceleration:magnitude_stats:moment3\n",
      "watch_acceleration:magnitude_stats:moment4\n",
      "watch_acceleration:magnitude_stats:percentile25\n",
      "watch_acceleration:magnitude_stats:percentile50\n",
      "watch_acceleration:magnitude_stats:percentile75\n",
      "watch_acceleration:magnitude_stats:value_entropy\n",
      "watch_acceleration:magnitude_stats:time_entropy\n",
      "watch_acceleration:magnitude_spectrum:spectral_entropy\n",
      "watch_acceleration:3d:mean_x\n",
      "watch_acceleration:3d:mean_y\n",
      "watch_acceleration:3d:mean_z\n",
      "watch_acceleration:3d:std_x\n",
      "watch_acceleration:3d:std_y\n",
      "watch_acceleration:3d:std_z\n",
      "watch_acceleration:3d:ro_xy\n",
      "watch_acceleration:3d:ro_xz\n",
      "watch_acceleration:3d:ro_yz\n",
      "watch_heading:mean_cos\n",
      "watch_heading:std_cos\n",
      "watch_heading:mean_sin\n",
      "watch_heading:std_sin\n",
      "watch_heading:entropy_8bins\n",
      "location_quick_features:std_lat\n",
      "location_quick_features:std_long\n",
      "location_quick_features:mean_abs_lat_deriv\n",
      "location_quick_features:mean_abs_long_deriv\n",
      "audio_naive:mfcc0:mean\n",
      "audio_naive:mfcc1:mean\n",
      "audio_naive:mfcc2:mean\n",
      "audio_naive:mfcc3:mean\n",
      "audio_naive:mfcc4:mean\n",
      "audio_naive:mfcc5:mean\n",
      "audio_naive:mfcc6:mean\n",
      "audio_naive:mfcc7:mean\n",
      "audio_naive:mfcc8:mean\n",
      "audio_naive:mfcc9:mean\n",
      "audio_naive:mfcc10:mean\n",
      "audio_naive:mfcc11:mean\n",
      "audio_naive:mfcc12:mean\n",
      "audio_naive:mfcc0:std\n",
      "audio_naive:mfcc1:std\n",
      "audio_naive:mfcc2:std\n",
      "audio_naive:mfcc3:std\n",
      "audio_naive:mfcc4:std\n",
      "audio_naive:mfcc5:std\n",
      "audio_naive:mfcc6:std\n",
      "audio_naive:mfcc7:std\n",
      "audio_naive:mfcc8:std\n",
      "audio_naive:mfcc9:std\n",
      "audio_naive:mfcc10:std\n",
      "audio_naive:mfcc11:std\n",
      "audio_naive:mfcc12:std\n",
      "\n",
      "Frequency-Domain Columns:\n",
      "raw_acc:magnitude_spectrum:log_energy_band0\n",
      "raw_acc:magnitude_spectrum:log_energy_band1\n",
      "raw_acc:magnitude_spectrum:log_energy_band2\n",
      "raw_acc:magnitude_spectrum:log_energy_band3\n",
      "raw_acc:magnitude_spectrum:log_energy_band4\n",
      "raw_acc:magnitude_spectrum:spectral_entropy\n",
      "proc_gyro:magnitude_spectrum:log_energy_band0\n",
      "proc_gyro:magnitude_spectrum:log_energy_band1\n",
      "proc_gyro:magnitude_spectrum:log_energy_band2\n",
      "proc_gyro:magnitude_spectrum:log_energy_band3\n",
      "proc_gyro:magnitude_spectrum:log_energy_band4\n",
      "proc_gyro:magnitude_spectrum:spectral_entropy\n",
      "raw_magnet:magnitude_spectrum:log_energy_band0\n",
      "raw_magnet:magnitude_spectrum:log_energy_band1\n",
      "raw_magnet:magnitude_spectrum:log_energy_band2\n",
      "raw_magnet:magnitude_spectrum:log_energy_band3\n",
      "raw_magnet:magnitude_spectrum:log_energy_band4\n",
      "raw_magnet:magnitude_spectrum:spectral_entropy\n",
      "watch_acceleration:magnitude_spectrum:log_energy_band0\n",
      "watch_acceleration:magnitude_spectrum:log_energy_band1\n",
      "watch_acceleration:magnitude_spectrum:log_energy_band2\n",
      "watch_acceleration:magnitude_spectrum:log_energy_band3\n",
      "watch_acceleration:magnitude_spectrum:log_energy_band4\n",
      "watch_acceleration:magnitude_spectrum:spectral_entropy\n",
      "watch_acceleration:spectrum:x_log_energy_band0\n",
      "watch_acceleration:spectrum:x_log_energy_band1\n",
      "watch_acceleration:spectrum:x_log_energy_band2\n",
      "watch_acceleration:spectrum:x_log_energy_band3\n",
      "watch_acceleration:spectrum:x_log_energy_band4\n",
      "watch_acceleration:spectrum:y_log_energy_band0\n",
      "watch_acceleration:spectrum:y_log_energy_band1\n",
      "watch_acceleration:spectrum:y_log_energy_band2\n",
      "watch_acceleration:spectrum:y_log_energy_band3\n",
      "watch_acceleration:spectrum:y_log_energy_band4\n",
      "watch_acceleration:spectrum:z_log_energy_band0\n",
      "watch_acceleration:spectrum:z_log_energy_band1\n",
      "watch_acceleration:spectrum:z_log_energy_band2\n",
      "watch_acceleration:spectrum:z_log_energy_band3\n",
      "watch_acceleration:spectrum:z_log_energy_band4\n"
     ]
    }
   ],
   "source": [
    "time_domain_keywords = ['mean', 'std', 'moment', 'percentile', 'entropy', 'magnitude_stats', '3d']\n",
    "frequency_domain_keywords = ['spectrum', 'log_energy_band', 'spectral_entropy', 'magnitude_spectrum']\n",
    "\n",
    "time_domain_columns = [col for col in feature_names if any(keyword in col for keyword in time_domain_keywords)]\n",
    "frequency_domain_columns = [col for col in feature_names if any(keyword in col for keyword in frequency_domain_keywords)]\n",
    "\n",
    "# Display the identified columns\n",
    "print(\"Time-Domain Columns:\")\n",
    "for col in time_domain_columns:\n",
    "    print(col)\n",
    "\n",
    "print(\"\\nFrequency-Domain Columns:\")\n",
    "for col in frequency_domain_columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = np.corrcoef(X, rowvar=False)\n",
    "threshold = 0.95\n",
    "columns_to_remove = np.where(np.abs(corr_matrix) > threshold)\n",
    "columns_to_remove = [(i, j) for i, j in zip(columns_to_remove[0], columns_to_remove[1]) if i != j]\n",
    "dedup_columns = list(set([col[0] for col in columns_to_remove]))\n",
    "X = np.delete(X, dedup_columns, axis=1)\n",
    "# X = X[:,dedup_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select body state label\n",
    "# target_label = ['LYING_DOWN', 'SITTING', 'FIX_walking', 'FIX_running', 'BICYCLING', 'OR_standing']\n",
    "target_labels = ['LYING_DOWN', 'SITTING', 'FIX_walking']\n",
    "# Fill the Nan with mean value and normalize all the data \n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = 'mean')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rnn_model(X_train, X_test, y_train, y_test, M_train, M_test, y_train_sw1D):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_shape=(X_train.shape[1],), activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    callback = EarlyStopping(monitor='loss',\n",
    "                                patience=3)\n",
    "    model.fit(X_train, y_train,\n",
    "                        epochs = 20, \n",
    "                        batch_size = 5,\n",
    "                        validation_data = (X_test, y_test),\n",
    "                        callbacks=[callback],\n",
    "                        verbose=0,\n",
    "                        sample_weight = y_train_sw1D)\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # print(classification_report(y_test, (y_pred > 0.5).astype(int)))\n",
    "    accuracy, precision, recall, f1 = evaluate_model(model, X_test, y_test)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm_model(X_train, X_test, y_train, y_test, M_train, M_test, y_train_sw1D):\n",
    "    X_train_1 = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test_1 = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(1, input_shape=(1, X_train_1.shape[2]), activation=\"sigmoid\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = 'sgd',\n",
    "                metrics = ['accuracy'])\n",
    "    callback = EarlyStopping(monitor='loss',\n",
    "                                patience=3)\n",
    "    history = model.fit(X_train_1, y_train,\n",
    "                    epochs = 20, \n",
    "                    batch_size = 5,\n",
    "                    validation_data = (X_test_1, y_test), \n",
    "                    callbacks=[callback],\n",
    "                    verbose=0,\n",
    "                    sample_weight = y_train_sw1D)\n",
    "    # Store the performance metric for this split\n",
    "    accuracy, precision, recall, f1 = evaluate_model(model, X_test_1, y_test)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest_model(X_train, X_test, y_train, y_test, M_train, M_test, y_train_sw1D):\n",
    "    rf = RandomForestClassifier(class_weight = 'balanced', n_estimators = 10, min_samples_split = 10)\n",
    "    rf.fit(X_train, y_train, sample_weight = y_train_sw1D)\n",
    "    accuracy, precision, recall, f1 = evaluate_model(rf, X_test, y_test)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm_model(X_train, X_test, y_train, y_test, M_train, M_test, y_train_sw1D):\n",
    "    svm = SVC(kernel='linear', random_state=42)\n",
    "    history = svm.fit(X_train, y_train, sample_weight = y_train_sw1D)\n",
    "    # y_pred = svm.predict(X_test)\n",
    "    accuracy, precision, recall, f1 = evaluate_model(svm, X_test, y_test)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_model = {\n",
    "    'rnn': run_rnn_model,\n",
    "    'lstm': run_lstm_model,\n",
    "    'random_forest': run_random_forest_model,\n",
    "    'svm': run_svm_model\n",
    "}\n",
    "models = ['rnn', 'lstm', 'random_forest', 'svm']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation for Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Checkout/Downloads/ExtraSensory-master/RNN_LSTM.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Checkout/Downloads/ExtraSensory-master/RNN_LSTM.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         recall_scores[model] \u001b[39m=\u001b[39m recall_scores[model]\u001b[39m+\u001b[39m[recall] \u001b[39mif\u001b[39;00m recall_scores\u001b[39m.\u001b[39mget(model) \u001b[39melse\u001b[39;00m [recall]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Checkout/Downloads/ExtraSensory-master/RNN_LSTM.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         f1_scores[model] \u001b[39m=\u001b[39m f1_scores[model]\u001b[39m+\u001b[39m[f1] \u001b[39mif\u001b[39;00m f1_scores\u001b[39m.\u001b[39mget(model) \u001b[39melse\u001b[39;00m [f1]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Checkout/Downloads/ExtraSensory-master/RNN_LSTM.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m plot_metric(models, [np\u001b[39m.\u001b[39mmean(val) \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m accuracy_scores\u001b[39m.\u001b[39mvalues()], \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAccuracy for \u001b[39m\u001b[39m{\u001b[39;00mtarget_label\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Checkout/Downloads/ExtraSensory-master/RNN_LSTM.ipynb#X22sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m plot_metric(models, [np\u001b[39m.\u001b[39mmean(val) \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m precision_scores\u001b[39m.\u001b[39mvalues()], \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPrecision for \u001b[39m\u001b[39m{\u001b[39;00mtarget_label\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Checkout/Downloads/ExtraSensory-master/RNN_LSTM.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m plot_metric(models, [np\u001b[39m.\u001b[39mmean(val) \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m recall_scores\u001b[39m.\u001b[39mvalues()], \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRecall for \u001b[39m\u001b[39m{\u001b[39;00mtarget_label\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_metric' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for target_label in target_labels:\n",
    "    accuracy_scores = {}\n",
    "    precision_scores = {}\n",
    "    recall_scores = {}\n",
    "    f1_scores = {}\n",
    "    X_new, y_new, M_new = select_target_labels(X, y, M, target_label, label_names, drop_all_zero = False)\n",
    "    X_new = pipeline.fit_transform(X_new, y_new)\n",
    "    for train_index, test_index in tscv.split(X_new, y_new):\n",
    "        # Split the data into training and test sets based on the current split indices\n",
    "        X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "        y_train, y_test = y_new[train_index], y_new[test_index]\n",
    "        M_train, M_test = M_new[train_index], M_new[test_index]\n",
    "        # To swap 0 and 1, simply do \n",
    "        y_train_sampleweight = np.abs(1-M_train)\n",
    "        y_train_sw1D = np.zeros(y_train_sampleweight.shape[0])\n",
    "        for i in range(len(y_train_sw1D)):\n",
    "            y_train_sw1D[i] = np.sum(y_train_sampleweight[i])/M_train.shape[1]\n",
    "        \n",
    "        for model in models:\n",
    "            accuracy, precision, recall, f1 = run_model[model](X_train,X_test,y_train,y_test,M_train,M_test,y_train_sw1D)\n",
    "            accuracy_scores[model] = accuracy_scores[model]+[accuracy] if accuracy_scores.get(model) else [accuracy]\n",
    "            precision_scores[model] = precision_scores[model]+[precision] if precision_scores.get(model) else [precision]\n",
    "            recall_scores[model] = recall_scores[model]+[recall] if recall_scores.get(model) else [recall]\n",
    "            f1_scores[model] = f1_scores[model]+[f1] if f1_scores.get(model) else [f1]\n",
    "    \n",
    "    plot_metric(models, [np.mean(val) for val in accuracy_scores.values()], f'Accuracy for {target_label}')\n",
    "    plot_metric(models, [np.mean(val) for val in precision_scores.values()], f'Precision for {target_label}')\n",
    "    plot_metric(models, [np.mean(val) for val in recall_scores.values()], f'Recall for {target_label}')\n",
    "    plot_metric(models, [np.mean(val) for val in f1_scores.values()], f'F1 for {target_label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
